{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'evaluation' from '/home/cstainsby/class/NLP/CPSC475/homework/hw12/evaluation.py'>"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "\n",
    "import os \n",
    "from nltk.corpus import movie_reviews\n",
    "import random \n",
    "\n",
    "import classifier\n",
    "# from classifier import train_naive_bayes\n",
    "import utils \n",
    "import evaluation\n",
    "\n",
    "importlib.reload(classifier)\n",
    "importlib.reload(evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['films', 'adapted', 'from', 'comic', 'books', 'have', ...], ['every', 'now', 'and', 'then', 'a', 'movie', 'comes', ...], ['you', \"'\", 've', 'got', 'mail', 'works', 'alot', ...], ['\"', 'jaws', '\"', 'is', 'a', 'rare', 'film', 'that', ...], ['moviemaking', 'is', 'a', 'lot', 'like', 'being', ...]]\n"
     ]
    }
   ],
   "source": [
    "def read_in_txt(fname):\n",
    "  with open(fname) as in_file:\n",
    "    in_file_str = in_file.read()\n",
    "    file_contents = in_file_str.split(\"\\n\")\n",
    "\n",
    "  return file_contents\n",
    "\n",
    "pos_train_files = read_in_txt(\"movie_reviews/pos.txt\")\n",
    "neg_train_files = read_in_txt(\"movie_reviews/neg.txt\")\n",
    "\n",
    "pos_test_files = read_in_txt(\"movie_reviews/posTst.txt\")\n",
    "neg_test_files = read_in_txt(\"movie_reviews/negTst.txt\")\n",
    " \n",
    "pos_train = [movie_reviews.words(fname) for fname in pos_train_files]\n",
    "neg_train = [movie_reviews.words(fname) for fname in neg_train_files]\n",
    "\n",
    "pos_test = [movie_reviews.words(fname) for fname in pos_test_files]\n",
    "neg_test = [movie_reviews.words(fname) for fname in neg_test_files]\n",
    "\n",
    "print(pos_train[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mike', 'myers', ',', 'you', 'certainly', 'did', ...]\n"
     ]
    }
   ],
   "source": [
    "X_train_words = pos_train + neg_train\n",
    "y_train = [1 for i in range(len(pos_train))] + [0 for i in range(len(neg_train))]\n",
    "\n",
    "X_test_words = pos_test + neg_test\n",
    "print(X_test_words[0])\n",
    "y_test = [1 for i in range(len(pos_test))] + [0 for i in range(len(neg_test))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['films', 'adapted', 'from', 'comic', 'books', 'have', ...], ['every', 'now', 'and', 'then', 'a', 'movie', 'comes', ...], ['you', \"'\", 've', 'got', 'mail', 'works', 'alot', ...], ['\"', 'jaws', '\"', 'is', 'a', 'rare', 'film', 'that', ...], ['moviemaking', 'is', 'a', 'lot', 'like', 'being', ...]]\n",
      "[1, 1, 1, 1, 1]\n",
      "\n",
      "[['mike', 'myers', ',', 'you', 'certainly', 'did', ...], ['carolco', 'pictures', 'and', 'dutch', 'director', ...], ['stendhal', \"'\", 's', 'syndrome', ':', 'a', ...], ['i', 'don', \"'\", 't', 'know', 'what', 'movie', 'the', ...], ['as', 'a', 'revolutionary', 'war', 'hero', 'in', ...]]\n",
      "[1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "print(X_train_words[:5])\n",
    "print(y_train[:5])\n",
    "print()\n",
    "print(X_test_words[:5])\n",
    "print(y_test[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = []\n",
    "X_test = []\n",
    "\n",
    "sent_dict = {}\n",
    "\n",
    "neg_words = read_in_txt(\"movie_reviews/negWords.txt\")\n",
    "for word in neg_words:\n",
    "  sent_dict[word] = 0\n",
    "\n",
    "pos_words = read_in_txt(\"movie_reviews/posWords.txt\")\n",
    "for word in pos_words:\n",
    "  sent_dict[word] = 1\n",
    "\n",
    "for i in range(len(X_train_words)):\n",
    "  X_train.append([])\n",
    "\n",
    "  for j in range(len(X_train_words[i])):\n",
    "    word = X_train_words[i][j]\n",
    "    if word in sent_dict:\n",
    "      X_train[i].append(sent_dict[word])\n",
    "    else: \n",
    "      X_train[i].append(0)\n",
    "\n",
    "\n",
    "for i in range(len(X_test_words)):\n",
    "  X_test.append([])\n",
    "\n",
    "  for j in range(len(X_test_words[i])):\n",
    "    word = X_test_words[i][j]\n",
    "    if word in sent_dict:\n",
    "      X_test[i].append(sent_dict[word])\n",
    "    else: \n",
    "      X_test[i].append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "862\n",
      "1\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train[:100]\n",
    "y_train = y_train[:100]\n",
    "print(len(X_train))\n",
    "print(len(X_train[0]))\n",
    "print((y_train[0]))\n",
    "print(len(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "priors, likelihoods = classifier.train_naive_bayes(pos_words, neg_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "predicted = classifier.predict_naive_bayes(priors, likelihoods, X_test_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Positives: 93\n",
      "False Positives: 7\n",
      "False Negatives: 56\n",
      "True Negatives: 44\n"
     ]
    }
   ],
   "source": [
    "matrix = evaluation.confusion_matrix(y_test, predicted, [0, 1])\n",
    "\n",
    "positives = matrix[0]\n",
    "negatives = matrix[1]\n",
    "\n",
    "print(\"True Positives:\", positives[0])\n",
    "print(\"False Positives:\", positives[1])\n",
    "print(\"False Negatives:\", negatives[0])\n",
    "print(\"True Negatives:\", negatives[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
